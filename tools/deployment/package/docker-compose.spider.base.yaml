name: "clp-package-base"

# Common service defaults.
x-service-defaults: &service_defaults
  image: "${CLP_PACKAGE_CONTAINER_IMAGE_REF:-clp-package}"
  logging:
    driver: "local"
  stop_grace_period: "60s"
  user: "${CLP_FIRST_PARTY_SERVICE_UID_GID:-1000:1000}"

# Common healthcheck defaults.
x-healthcheck-defaults: &healthcheck_defaults
  # Avoid lowering to prevent excessive resource usage.
  interval: "30s"

  # Mark unhealthy after 3 failed probes.
  # - In steady state, (<interval> + <timeout>) Ã— 3 = ~90s before the service is marked unhealthy.
  # - From startup, <start_period> (60s) + ~90s = ~150s before the service is marked unhealthy.
  retries: 3

  # Frequent checks during startup allow fast transition to healthy.
  start_interval: "2s"

  # Ignore failures for <start_period> / (<start_interval> + <timeout>) = ~15 frequent checks before
  # counting retries.
  start_period: "60s"

  # Short timeout since no remote communication is expected.
  timeout: "2s"

# Common volume definitions.
x-volume-definitions:
  clp-config-readonly: &volume_clp_config_readonly
    type: "bind"
    source: "${CLP_LOGS_DIR_HOST:-./var/log}/.clp-config.yml"
    target: "/etc/clp-config.yml"
    read_only: true
  clp-logs: &volume_clp_logs
    type: "bind"
    source: "${CLP_LOGS_DIR_HOST:-./var/log}"
    target: "/var/log"

volumes:
  # Dummy volume to use when a bind mount is not desired.
  empty:
    driver_opts:
      device: "tmpfs"
      type: "tmpfs"
      size: 0

services:
  database:
    <<: *service_defaults
    image: "${CLP_DB_CONTAINER_IMAGE_REF:-mariadb:10-jammy}"
    hostname: "database"
    user: "${CLP_THIRD_PARTY_SERVICE_UID_GID:-1000:1000}"
    environment:
      MYSQL_DATABASE: "${CLP_DB_NAME:-clp-db}"
      MYSQL_PASSWORD: "${CLP_DB_PASS:?Please set a value.}"
      MYSQL_ROOT_PASSWORD: "${CLP_DB_PASS:?Please set a value.}"
      MYSQL_USER: "${CLP_DB_USER:?Please set a value.}"
    ports:
      - host_ip: "${CLP_DB_HOST:-127.0.0.1}"
        published: "${CLP_DB_PORT:-3306}"
        target: 3306
    volumes:
      - type: "bind"
        source: "${CLP_DB_CONF_LOGGING_FILE_HOST:-./etc/mysql/conf.d/logging.cnf}"
        target: "/etc/mysql/conf.d/logging.cnf"
        read_only: true
      - type: "bind"
        source: "${CLP_DB_DATA_DIR_HOST:-./var/data/database}"
        target: "/var/lib/mysql"
      - type: "bind"
        source: "${CLP_DB_LOGS_DIR_HOST:-./var/log/database}"
        target: "/var/log/mysql"
    healthcheck:
      <<: *healthcheck_defaults
      test: [
        "CMD",
        "mysqladmin", "ping",
        "--silent",
        "-h", "127.0.0.1",
        "-u", "${CLP_DB_USER:?Please set a value.}",
        "--password=${CLP_DB_PASS:?Please set a value.}"
      ]

  db-table-creator:
    <<: *service_defaults
    hostname: "db_table_creator"
    environment:
      CLP_DB_PASS: "${CLP_DB_PASS:?Please set a value.}"
      CLP_DB_USER: "${CLP_DB_USER:?Please set a value.}"
      PYTHONPATH: "/opt/clp/lib/python3/site-packages"
    volumes:
      - *volume_clp_config_readonly
    depends_on:
      database:
        condition: "service_healthy"
    command: [
      "python3",
      "-u",
      "-m", "clp_py_utils.create-db-tables",
      "--config", "/etc/clp-config.yml",
      "--storage-engine", "${CLP_PACKAGE_STORAGE_ENGINE:-clp}",
    ]

  spider-scheduler:
    <<: *service_defaults
    hostname: "spider_scheduler"
    environment:
      SPIDER_LOG_FILE: "/var/log/compression_scheduler.log"
    depends_on:
      db-table-creator:
        condition: "service_completed_successfully"
    ports:
      - host_ip: "${SPIDER_SCHEDULER_HOST}"
        published: "${SPIDER_SCHEDULER_PORT}"
        target: "${SPIDER_SCHEDULER_PORT}"
    command: [
      "/opt/clp/bin/spider_scheduler",
      "--host", "${SPIDER_SCHEDULER_HOST}",
      "--port", "${SPIDER_SCHEDULER_PORT}",
      "--storage_url", "${SPIDER_DB_URL}"
    ]

  compression-scheduler:
    <<: *service_defaults
    hostname: "compression_scheduler"
    stop_grace_period: "300s"
    environment:
      CLP_DB_PASS: "${CLP_DB_PASS:?Please set a value.}"
      CLP_DB_USER: "${CLP_DB_USER:?Please set a value.}"
      CLP_LOGGING_LEVEL: "${CLP_COMPRESSION_SCHEDULER_LOGGING_LEVEL:-INFO}"
      CLP_LOGS_DIR: "/var/log"
      PYTHONPATH: "/opt/clp/lib/python3/site-packages"
    volumes:
      - *volume_clp_config_readonly
      - *volume_clp_logs
      - "${CLP_AWS_CONFIG_DIR_HOST:-empty}:/.aws:ro"
      - "${CLP_LOGS_INPUT_DIR_HOST:-empty}:${CLP_LOGS_INPUT_DIR_CONTAINER:-/mnt/logs}"
    depends_on:
      db-table-creator:
        condition: "service_completed_successfully"
    command: [
      "python3",
      "-u",
      "-m", "job_orchestration.scheduler.compress.compression_scheduler",
      "--config", "/etc/clp-config.yml"
    ]

  compression-worker:
    <<: *service_defaults
    hostname: "compression_worker"
    environment:
      CLP_CONFIG_PATH: "/etc/clp-config.yml"
      CLP_ENABLE_PROFILING: "${CLP_COMPRESSION_WORKER_ENABLE_PROFILING:-false}"
      CLP_HOME: "/opt/clp"
      CLP_LOGGING_LEVEL: "${CLP_COMPRESSION_WORKER_LOGGING_LEVEL:-INFO}"
      CLP_LOGS_DIR: "/var/log/compression_worker"
      PYTHONPATH: "/opt/clp/lib/python3/site-packages"
      SPIDER_LOG_DIR: "/var/log/compression_worker"
    volumes:
      - *volume_clp_config_readonly
      - *volume_clp_logs
      - "${CLP_AWS_CONFIG_DIR_HOST:-empty}:/.aws:ro"
      - "${CLP_LOGS_INPUT_DIR_HOST:-empty}:${CLP_LOGS_INPUT_DIR_CONTAINER:-/mnt/logs}"

      # NOTE: Only one of `CLP_ARCHIVE_OUTPUT_DIR_HOST` and `CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST` are
      # set at a time, but since `./var/data` on the host is mounted into the container and both
      # `CLP_ARCHIVE_OUTPUT_DIR_HOST` and `CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST` default to
      # directories under `./var/data`, we need to use a hack to avoid having Docker create the
      # unset directory on the host (as root).
      #
      # For example, let's say we use the following as the mount for staged archives:
      # "${CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST:-empty}:/var/data/staged-archives". If
      # `CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST` is unset, Docker will create
      # `/var/data/staged-archives` in the container, but it will also create
      # `./var/data/staged-archives` on the host as root; this is because `/var/data` in the
      # container is bind mounted to `./var/data` on the host.
      #
      # The hack to avoid this is if one of `CLP_ARCHIVE_OUTPUT_DIR_HOST` or
      # `CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST` is unset, we set the target for the corresponding mount
      # to a path that's not under `/var/data` in the container.
      - "${CLP_ARCHIVE_OUTPUT_DIR_HOST:-empty}\
        :${CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST:+/tmp}/var/data/archives"
      - "${CLP_STAGED_ARCHIVE_OUTPUT_DIR_HOST:-empty}\
        :${CLP_ARCHIVE_OUTPUT_DIR_HOST:+/tmp}/var/data/staged-archives"
      - type: "bind"
        source: "${CLP_DATA_DIR_HOST:-./var/data}"
        target: "/var/data"
    depends_on:
      db-table-creator:
        condition: "service_completed_successfully"
    command: [
      "python3",
      "-u",
      "/opt/clp/lib/python3/site-packages/clp_py_utils/start-spider-worker.py",
      "--concurrency", "${CLP_COMPRESSION_WORKER_CONCURRENCY:-1}",
      "--storage-url", "${SPIDER_DB_URL}",
      # NOTE: Leave host to spider scheduler's host. This only affects task placement.
      "--host", "${SPIDER_SCHEDULER_HOST}",
    ]

  webui:
    <<: *service_defaults
    hostname: "webui"
    environment:
      AWS_ACCESS_KEY_ID: "${CLP_STREAM_OUTPUT_AWS_ACCESS_KEY_ID:-}"
      AWS_SECRET_ACCESS_KEY: "${CLP_STREAM_OUTPUT_AWS_SECRET_ACCESS_KEY:-}"
      CLP_DB_PASS: "${CLP_DB_PASS:?Please set a value.}"
      CLP_DB_USER: "${CLP_DB_USER:?Please set a value.}"
      HOST: "0.0.0.0"
      NODE_ENV: "production"
      NODE_PATH: "/opt/clp/var/www/webui/server/node_modules"
      PORT: "4000"
      RATE_LIMIT: "${CLP_WEBUI_RATE_LIMIT:-1000}"
    ports:
      - host_ip: "${CLP_WEBUI_HOST:-127.0.0.1}"
        published: "${CLP_WEBUI_PORT:-4000}"
        target: 4000
    volumes:
      - "${CLP_AWS_CONFIG_DIR_HOST:-empty}:/.aws:ro"
      - "${CLP_STREAM_OUTPUT_DIR_HOST:-empty}:/var/data/streams"
      - type: "bind"
        source: "./var/www/webui/client/settings.json"
        target: "/opt/clp/var/www/webui/client/settings.json"
        read_only: true
      - type: "bind"
        source: "./var/www/webui/server/dist/settings.json"
        target: "/opt/clp/var/www/webui/server/dist/settings.json"
        read_only: true
    depends_on:
      db-table-creator:
        condition: "service_completed_successfully"
      results-cache-indices-creator:
        condition: "service_completed_successfully"
    command: [
      "/opt/clp/bin/node-22",
      "/opt/clp/var/www/webui/server/dist/src/main.js"
    ]
    healthcheck:
      <<: *healthcheck_defaults
      test: [
        "CMD",
        "bash",
        "-c",
        "< /dev/tcp/webui/4000"
      ]

  garbage-collector:
    <<: *service_defaults
    hostname: "garbage_collector"
    deploy:
      # Value must be either 0 or 1. Set to 0 to disable the garbage collector.
      replicas: "${CLP_GARBAGE_COLLECTOR_ENABLED:-1}"
    environment:
      CLP_DB_PASS: "${CLP_DB_PASS:?Please set a value.}"
      CLP_DB_USER: "${CLP_DB_USER:?Please set a value.}"
      CLP_HOME: "/opt/clp"
      CLP_LOGGING_LEVEL: "${CLP_GARBAGE_COLLECTOR_LOGGING_LEVEL:-INFO}"
      CLP_LOGS_DIR: "/var/log/garbage_collector"
      PYTHONPATH: "/opt/clp/lib/python3/site-packages"
    volumes:
      - *volume_clp_config_readonly
      - *volume_clp_logs
      - "${CLP_ARCHIVE_OUTPUT_DIR_HOST:-empty}:/var/data/archives"
      - "${CLP_AWS_CONFIG_DIR_HOST:-empty}:/.aws:ro"
      - "${CLP_STREAM_OUTPUT_DIR_HOST:-empty}:/var/data/streams"
    depends_on:
      db-table-creator:
        condition: "service_completed_successfully"
      results-cache-indices-creator:
        condition: "service_completed_successfully"
    command: [
      "python3", "-u",
      "-m", "job_orchestration.garbage_collector.garbage_collector",
      "--config", "/etc/clp-config.yml",
    ]
